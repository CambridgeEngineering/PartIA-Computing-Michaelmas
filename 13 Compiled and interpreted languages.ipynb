{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "*This notebook is optional and intended for those with an interest in going beyond the course material.*\n",
    "\n",
    "Programming languages and commonly classed as *compiled* or *interpreted*. We summarise and demomstrate some of the differences in thie notebook.\n",
    "\n",
    "## Compiled languages\n",
    "\n",
    "A compiled language uses a *compiler* to transform input code into a program (machine code) that is executed by a computer. Machine code is the set of instructions for a computer to execute in the CPUs computers 'native' language (instruction set). It is not human readable. The compiler generally processes the entire program, transforming it in a sequence of steps into machine code.\n",
    "\n",
    "Common compiled languages include C, C++ and Rust.\n",
    "\n",
    "\n",
    "## Interpreted languages\n",
    "\n",
    "An interpreted language processes program instructions as they are encountered (line-by-line) rather processing the entire program into machine code ahead of time.\n",
    "\n",
    "Python in an interpreted language.\n",
    "\n",
    "\n",
    "## Differences\n",
    "\n",
    "Compiled languages lead to programs are generally faster than interpretted programs, although in many cases implementations in interpreted language are nowdays fast enough. Compiled programs can have a smaller footprint, which can be important for embedded devices and other platforms with limited capacity. The computer on which a compiled program runs does not need to have a compiler or an interpreter installed.\n",
    "\n",
    "When a compiler translates code into an executable program it will typiclly perform checks and perform optimisations (static analysis). The compiler checks for valid syntax, and sophiscataed optimisations can perform code transformation to make programs faster. Interpreted languages are usually simpler to develop, and more interactive and avoid the need for a compilation step. Interpreted languages are often dynamically typed, with the interpreter inferring the types, e.g. integers versus floats. With compiled languages types are usually fixed at compile time.\n",
    "\n",
    "\n",
    "## Just-in-time compilation\n",
    "\n",
    "The difference between interpreted and compiled languages is not as clear as it once was, with interpreted languages now often using 'just-in-time' compilation. We will explore the impact of compiled code using [Numba](https://numba.pydata.org/), a just-in-time compiler for Python. For specific functions that we mark, Numba can compile the code and apply peformance optimisations typical of compiled languages with the objective of making functions faster.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand the difference between compiled and interpreted implementations\n",
    "- Awareness of intermediate representations and assembly code \n",
    "- Explore performance differences between interpreted and compiled implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will later use Numba, so we install it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /Users/garth/local/venv-jupyter/lib/python3.8/site-packages (0.51.2)\r\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /Users/garth/local/venv-jupyter/lib/python3.8/site-packages (from numba) (0.34.0)\r\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/garth/local/venv-jupyter/lib/python3.8/site-packages (from numba) (1.19.1)\r\n",
      "Requirement already satisfied: setuptools in /Users/garth/local/venv-jupyter/lib/python3.8/site-packages (from numba) (50.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of interpreted and compiled functions\n",
    "\n",
    "In [07 Numerical computation](07%20Numerical%20computation.ipynb) we tested the performance of a simple function for computing the norm of a long vector. We consider a similar problem here: computing the dot product of a vector with itself, $\\boldsymbol{x} \\cdot \\boldsymbol{x}$, using our own Python function and using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 9.53 ms, total: 2.91 s\n",
      "Wall time: 2.92 s\n",
      "CPU times: user 24.5 ms, sys: 929 µs, total: 25.5 ms\n",
      "Wall time: 5.98 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def compute_norm2(x):\n",
    "    norm2 = 0.0\n",
    "    for xi in x:\n",
    "        norm2 += xi*xi\n",
    "    return norm2\n",
    "\n",
    "x = np.random.rand(10000000)\n",
    "%time n0 = compute_norm2(x)\n",
    "%time n1 = np.dot(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the NumPy code is many orders of magnitude faster. NumPy in fact uses compiled code for the computation, which is the reason why it is much faster than our pure Python implementation.\n",
    "\n",
    "We now make a small change and add the 'decorator' `@numba.jit` to our function. This instructs Numba to transform our function in a compiled function/program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 33 µs, total: 14.6 ms\n",
      "Wall time: 14.6 ms\n",
      "CPU times: user 7.31 ms, sys: 313 µs, total: 7.62 ms\n",
      "Wall time: 1.85 ms\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def compute_norm2(x):\n",
    "    norm2 = 0.0\n",
    "    for xi in x:\n",
    "        norm2 += xi*xi\n",
    "    return norm2\n",
    "\n",
    "x = np.random.rand(10000000)\n",
    "compute_norm2(x)\n",
    "%time n0 = compute_norm2(x)\n",
    "%time n1 = np.dot(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we call `compute_norm2` twice and time only the second call. We want to measure the raw cost of the computation and not the small Numba just-in-time compilation overhead that is incurred the first time a functon is processed.\n",
    "\n",
    "The Numba version is much faster than the pure Python version. NumPy is faster again for this operation, but relative close to the Numba time. This is likely because NumPy is using a highly optimised BLAS (Basic Linear Algebra Subprograms) implementation, which is a set of machine code level functions that are tuned for numerical computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting implementations\n",
    "\n",
    "We saw in [10 Algorithms](10%20Algorithms.ipynb) that our implementation of the quicksort algorithm was considerably slower than the Python built-in quicksort. Part of the performance difference could be explained by our implementation being in pure Python, with the built-in Python function being implemented in a compiled language.\n",
    "\n",
    "We can explore the difference compilation might make to our implementation. To start, we re-produce the pure Python quicksort implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_ref(A, lo, hi):\n",
    "    \"Partitioning function for use in quicksort\"\n",
    "    pivot = A[hi]\n",
    "    i = lo\n",
    "    for j in range(lo,  hi):\n",
    "        if A[j] <= pivot:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i += 1\n",
    "    A[i], A[hi] = A[hi], A[i]\n",
    "    return i\n",
    "\n",
    "def quicksort_ref(A, lo=0, hi=None):\n",
    "    \"Sort A and return sorted array\"\n",
    "\n",
    "    # Initialise data the first time function is called    \n",
    "    if hi is None:\n",
    "        A = A.copy()\n",
    "        hi = len(A) - 1\n",
    "\n",
    "    # Sort    \n",
    "    if lo < hi:\n",
    "        p = partition_ref(A, lo,  hi)\n",
    "        quicksort_ref(A, lo, p - 1)\n",
    "        quicksort_ref(A, p + 1, hi)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce a version annotated with a Numba decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def partition_jit(A, lo, hi):\n",
    "    \"Partitioning function for use in quicksort\"\n",
    "    pivot = A[hi]\n",
    "    i = lo\n",
    "    for j in range(lo,  hi):\n",
    "        if A[j] <= pivot:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i += 1\n",
    "    A[i], A[hi] = A[hi], A[i]\n",
    "    return i\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def quicksort_jit(A, lo=0, hi=-1):\n",
    "    \"Sort A and return sorted array\"\n",
    "\n",
    "    # Initialise data the first time function is called    \n",
    "    if hi == -1:\n",
    "        A = A.copy()\n",
    "        hi = len(A) - 1\n",
    "\n",
    "    # Sort    \n",
    "    if lo < hi:\n",
    "        p = partition_jit(A, lo,  hi)\n",
    "        quicksort_jit(A, lo, p - 1)\n",
    "        quicksort_jit(A, p + 1, hi)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last argument to `quicksort_jit` has been changed slightly so that the argument type does not change (argument types that change are problematic for a compiler as it needs to know ahead of time which types to generate machine code for).\n",
    "\n",
    "We can now time our pure Python implementation, the Numba-compiled implementation and the built-in sort function. As before, we will call `quicksort_jit` once before timing to eliminate the cost of the just-in-time compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.24 s, sys: 14.3 ms, total: 5.26 s\n",
      "Wall time: 5.28 s\n",
      "CPU times: user 58.4 ms, sys: 332 µs, total: 58.8 ms\n",
      "Wall time: 58.9 ms\n",
      "CPU times: user 33.8 ms, sys: 221 µs, total: 34.1 ms\n",
      "Wall time: 33.9 ms\n"
     ]
    }
   ],
   "source": [
    "data = np.random.rand(500000)\n",
    "\n",
    "# Time the pure Python implementation\n",
    "%time x = quicksort_ref(data)\n",
    "\n",
    "# Time the Numba implementation\n",
    "quicksort_jit(data)\n",
    "%time x = quicksort_jit(data)\n",
    "\n",
    "# Time the built-in implementation\n",
    "%time x = np.sort(data, kind='quicksort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure Python implementation is clearly the slowest. The Numba and built-in implementation are relatively closde in time. Note that the Numba implementation is virtually a direct translation of the pure Python implementation and has not been carefully optimised. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate representations and assembly code\n",
    "\n",
    "A compiler translates input code into (i) an 'intermediate representation' (IR), and then into (ii) machine code. The IR is the compiler's internal representation of a program. A compiler can perform optimisations on the IR that may make a program faster and which may be specific to the CPU type. Machine code is the low instructions sent to the CPU.\n",
    "\n",
    "With Numba we can inspect the IR and the assembly code. Assembly code is human readable code (but very low level) that maps almost one-to-one to machine code (which would be very hard to read).\n",
    "\n",
    "Consider a very simple function that returns the sum of two integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import int64\n",
    "\n",
    "@numba.jit('int64(int64, int64)', nopython=True)\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that we have specified the argument types in this case.\n",
    "\n",
    "We can inspect the compiler's IR for the this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "; ModuleID = 'add'\n",
      "source_filename = \"<string>\"\n",
      "target datalayout = \"e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\n",
      "target triple = \"x86_64-apple-darwin19.6.0\"\n",
      "\n",
      "@\"_ZN08NumbaEnv8__main__7add$247Exx\" = common local_unnamed_addr global i8* null\n",
      "@.const.add = internal constant [4 x i8] c\"add\\00\"\n",
      "@PyExc_RuntimeError = external global i8\n",
      "@\".const.missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\" = internal constant [55 x i8] c\"missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\\00\"\n",
      "\n",
      "; Function Attrs: nofree norecurse nounwind writeonly\n",
      "define i32 @\"_ZN8__main__7add$247Exx\"(i64* noalias nocapture %retptr, { i8*, i32, i8* }** noalias nocapture readnone %excinfo, i64 %arg.x, i64 %arg.y) local_unnamed_addr #0 {\n",
      "entry:\n",
      "  %.14 = add nsw i64 %arg.y, %arg.x\n",
      "  store i64 %.14, i64* %retptr, align 8\n",
      "  ret i32 0\n",
      "}\n",
      "\n",
      "define i8* @\"_ZN7cpython8__main__7add$247Exx\"(i8* nocapture readnone %py_closure, i8* %py_args, i8* nocapture readnone %py_kws) local_unnamed_addr {\n",
      "entry:\n",
      "  %.5 = alloca i8*, align 8\n",
      "  %.6 = alloca i8*, align 8\n",
      "  %.7 = call i32 (i8*, i8*, i64, i64, ...) @PyArg_UnpackTuple(i8* %py_args, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.const.add, i64 0, i64 0), i64 2, i64 2, i8** nonnull %.5, i8** nonnull %.6)\n",
      "  %.8 = icmp eq i32 %.7, 0\n",
      "  br i1 %.8, label %entry.if, label %entry.endif, !prof !0\n",
      "\n",
      "entry.if:                                         ; preds = %entry.endif.endif.endif.endif.endif, %entry.endif.endif.endif, %entry\n",
      "  ret i8* null\n",
      "\n",
      "entry.endif:                                      ; preds = %entry\n",
      "  %.12 = load i8*, i8** @\"_ZN08NumbaEnv8__main__7add$247Exx\", align 8\n",
      "  %.17 = icmp eq i8* %.12, null\n",
      "  br i1 %.17, label %entry.endif.if, label %entry.endif.endif, !prof !0\n",
      "\n",
      "entry.endif.if:                                   ; preds = %entry.endif\n",
      "  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([55 x i8], [55 x i8]* @\".const.missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\", i64 0, i64 0))\n",
      "  ret i8* null\n",
      "\n",
      "entry.endif.endif:                                ; preds = %entry.endif\n",
      "  %.21 = load i8*, i8** %.5, align 8\n",
      "  %.24 = call i8* @PyNumber_Long(i8* %.21)\n",
      "  %.25 = icmp eq i8* %.24, null\n",
      "  br i1 %.25, label %entry.endif.endif.endif, label %entry.endif.endif.if, !prof !0\n",
      "\n",
      "entry.endif.endif.if:                             ; preds = %entry.endif.endif\n",
      "  %.27 = call i64 @PyLong_AsLongLong(i8* nonnull %.24)\n",
      "  call void @Py_DecRef(i8* nonnull %.24)\n",
      "  br label %entry.endif.endif.endif\n",
      "\n",
      "entry.endif.endif.endif:                          ; preds = %entry.endif.endif, %entry.endif.endif.if\n",
      "  %.22.0 = phi i64 [ %.27, %entry.endif.endif.if ], [ 0, %entry.endif.endif ]\n",
      "  %.32 = call i8* @PyErr_Occurred()\n",
      "  %.33 = icmp eq i8* %.32, null\n",
      "  br i1 %.33, label %entry.endif.endif.endif.endif, label %entry.if, !prof !1\n",
      "\n",
      "entry.endif.endif.endif.endif:                    ; preds = %entry.endif.endif.endif\n",
      "  %.37 = load i8*, i8** %.6, align 8\n",
      "  %.40 = call i8* @PyNumber_Long(i8* %.37)\n",
      "  %.41 = icmp eq i8* %.40, null\n",
      "  br i1 %.41, label %entry.endif.endif.endif.endif.endif, label %entry.endif.endif.endif.endif.if, !prof !0\n",
      "\n",
      "entry.endif.endif.endif.endif.if:                 ; preds = %entry.endif.endif.endif.endif\n",
      "  %.43 = call i64 @PyLong_AsLongLong(i8* nonnull %.40)\n",
      "  call void @Py_DecRef(i8* nonnull %.40)\n",
      "  br label %entry.endif.endif.endif.endif.endif\n",
      "\n",
      "entry.endif.endif.endif.endif.endif:              ; preds = %entry.endif.endif.endif.endif, %entry.endif.endif.endif.endif.if\n",
      "  %.38.0 = phi i64 [ %.43, %entry.endif.endif.endif.endif.if ], [ 0, %entry.endif.endif.endif.endif ]\n",
      "  %.48 = call i8* @PyErr_Occurred()\n",
      "  %.49 = icmp eq i8* %.48, null\n",
      "  br i1 %.49, label %entry.endif.endif.endif.endif.endif.endif, label %entry.if, !prof !1\n",
      "\n",
      "entry.endif.endif.endif.endif.endif.endif:        ; preds = %entry.endif.endif.endif.endif.endif\n",
      "  %.14.i = add nsw i64 %.38.0, %.22.0\n",
      "  %.74 = call i8* @PyLong_FromLongLong(i64 %.14.i)\n",
      "  ret i8* %.74\n",
      "}\n",
      "\n",
      "declare i32 @PyArg_UnpackTuple(i8*, i8*, i64, i64, ...) local_unnamed_addr\n",
      "\n",
      "declare void @PyErr_SetString(i8*, i8*) local_unnamed_addr\n",
      "\n",
      "declare i8* @PyNumber_Long(i8*) local_unnamed_addr\n",
      "\n",
      "declare i64 @PyLong_AsLongLong(i8*) local_unnamed_addr\n",
      "\n",
      "declare void @Py_DecRef(i8*) local_unnamed_addr\n",
      "\n",
      "declare i8* @PyErr_Occurred() local_unnamed_addr\n",
      "\n",
      "declare i8* @PyLong_FromLongLong(i64) local_unnamed_addr\n",
      "\n",
      "; Function Attrs: norecurse nounwind readnone\n",
      "define i64 @\"cfunc._ZN8__main__7add$247Exx\"(i64 %.1, i64 %.2) local_unnamed_addr #1 {\n",
      "entry:\n",
      "  %.14.i = add nsw i64 %.2, %.1\n",
      "  ret i64 %.14.i\n",
      "}\n",
      "\n",
      "; Function Attrs: nounwind\n",
      "declare void @llvm.stackprotector(i8*, i8**) #2\n",
      "\n",
      "attributes #0 = { nofree norecurse nounwind writeonly }\n",
      "attributes #1 = { norecurse nounwind readnone }\n",
      "attributes #2 = { nounwind }\n",
      "\n",
      "!0 = !{!\"branch_weights\", i32 1, i32 99}\n",
      "!1 = !{!\"branch_weights\", i32 99, i32 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v, k in add.inspect_llvm().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IR would be of interest to someone designing compilers or seeing the optimisation transformations that a compiler might perform.\n",
    "\n",
    "In some very special cases it can be helpful to inspect the assembly code, which is the closest to readable version of CPU instructions. It is usually inspected only in cases where an understanding of the lowest level operations is required, e.g. when extreme performance is necessary. It is specific to a CPU architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "\t.macosx_version_min 10, 15\n",
      "\t.globl\t__ZN8__main__7add$247Exx\n",
      "\t.p2align\t4, 0x90\n",
      "__ZN8__main__7add$247Exx:\n",
      "\taddq\t%rcx, %rdx\n",
      "\tmovq\t%rdx, (%rdi)\n",
      "\txorl\t%eax, %eax\n",
      "\tretq\n",
      "\n",
      "\t.globl\t__ZN7cpython8__main__7add$247Exx\n",
      "\t.p2align\t4, 0x90\n",
      "__ZN7cpython8__main__7add$247Exx:\n",
      "\t.cfi_startproc\n",
      "\tpushq\t%rbp\n",
      "\t.cfi_def_cfa_offset 16\n",
      "\tpushq\t%r15\n",
      "\t.cfi_def_cfa_offset 24\n",
      "\tpushq\t%r14\n",
      "\t.cfi_def_cfa_offset 32\n",
      "\tpushq\t%r13\n",
      "\t.cfi_def_cfa_offset 40\n",
      "\tpushq\t%r12\n",
      "\t.cfi_def_cfa_offset 48\n",
      "\tpushq\t%rbx\n",
      "\t.cfi_def_cfa_offset 56\n",
      "\tsubq\t$24, %rsp\n",
      "\t.cfi_def_cfa_offset 80\n",
      "\t.cfi_offset %rbx, -56\n",
      "\t.cfi_offset %r12, -48\n",
      "\t.cfi_offset %r13, -40\n",
      "\t.cfi_offset %r14, -32\n",
      "\t.cfi_offset %r15, -24\n",
      "\t.cfi_offset %rbp, -16\n",
      "\tmovq\t%rsi, %rdi\n",
      "\tmovabsq\t$_.const.add, %rsi\n",
      "\tmovabsq\t$_PyArg_UnpackTuple, %rbp\n",
      "\tleaq\t16(%rsp), %r8\n",
      "\tleaq\t8(%rsp), %r9\n",
      "\tmovl\t$2, %edx\n",
      "\tmovl\t$2, %ecx\n",
      "\txorl\t%eax, %eax\n",
      "\tcallq\t*%rbp\n",
      "\ttestl\t%eax, %eax\n",
      "\tje\tLBB1_1\n",
      "\tmovabsq\t$__ZN08NumbaEnv8__main__7add$247Exx, %rax\n",
      "\tcmpq\t$0, (%rax)\n",
      "\tje\tLBB1_4\n",
      "\tmovq\t16(%rsp), %rdi\n",
      "\tmovabsq\t$_PyNumber_Long, %r13\n",
      "\tcallq\t*%r13\n",
      "\tmovabsq\t$_PyLong_AsLongLong, %r15\n",
      "\tmovabsq\t$_Py_DecRef, %r12\n",
      "\ttestq\t%rax, %rax\n",
      "\tje\tLBB1_6\n",
      "\tmovq\t%rax, %rbx\n",
      "\tmovq\t%rax, %rdi\n",
      "\tcallq\t*%r15\n",
      "\tmovq\t%rax, %r14\n",
      "\tmovq\t%rbx, %rdi\n",
      "\tcallq\t*%r12\n",
      "\tmovabsq\t$_PyErr_Occurred, %rbp\n",
      "\tcallq\t*%rbp\n",
      "\ttestq\t%rax, %rax\n",
      "\tjne\tLBB1_1\n",
      "LBB1_9:\n",
      "\tmovq\t8(%rsp), %rdi\n",
      "\tcallq\t*%r13\n",
      "\ttestq\t%rax, %rax\n",
      "\tje\tLBB1_10\n",
      "\tmovq\t%rax, %rbx\n",
      "\tmovq\t%rax, %rdi\n",
      "\tcallq\t*%r15\n",
      "\tmovq\t%rax, %r15\n",
      "\tmovq\t%rbx, %rdi\n",
      "\tcallq\t*%r12\n",
      "\tcallq\t*%rbp\n",
      "\ttestq\t%rax, %rax\n",
      "\tjne\tLBB1_1\n",
      "LBB1_13:\n",
      "\taddq\t%r14, %r15\n",
      "\tmovabsq\t$_PyLong_FromLongLong, %rax\n",
      "\tmovq\t%r15, %rdi\n",
      "\tcallq\t*%rax\n",
      "LBB1_2:\n",
      "\taddq\t$24, %rsp\n",
      "\tpopq\t%rbx\n",
      "\tpopq\t%r12\n",
      "\tpopq\t%r13\n",
      "\tpopq\t%r14\n",
      "\tpopq\t%r15\n",
      "\tpopq\t%rbp\n",
      "\tretq\n",
      "LBB1_4:\n",
      "\tmovabsq\t$_PyExc_RuntimeError, %rdi\n",
      "\tmovabsq\t$\"_.const.missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\", %rsi\n",
      "\tmovabsq\t$_PyErr_SetString, %rax\n",
      "\tcallq\t*%rax\n",
      "LBB1_1:\n",
      "\txorl\t%eax, %eax\n",
      "\tjmp\tLBB1_2\n",
      "LBB1_6:\n",
      "\txorl\t%r14d, %r14d\n",
      "\tmovabsq\t$_PyErr_Occurred, %rbp\n",
      "\tcallq\t*%rbp\n",
      "\ttestq\t%rax, %rax\n",
      "\tje\tLBB1_9\n",
      "\tjmp\tLBB1_1\n",
      "LBB1_10:\n",
      "\txorl\t%r15d, %r15d\n",
      "\tcallq\t*%rbp\n",
      "\ttestq\t%rax, %rax\n",
      "\tje\tLBB1_13\n",
      "\tjmp\tLBB1_1\n",
      "\t.cfi_endproc\n",
      "\n",
      "\t.globl\t_cfunc._ZN8__main__7add$247Exx\n",
      "\t.p2align\t4, 0x90\n",
      "_cfunc._ZN8__main__7add$247Exx:\n",
      "\tleaq\t(%rdi,%rsi), %rax\n",
      "\tretq\n",
      "\n",
      "\t.comm\t__ZN08NumbaEnv8__main__7add$247Exx,8,3\n",
      "\t.section\t__TEXT,__const\n",
      "_.const.add:\n",
      "\t.asciz\t\"add\"\n",
      "\n",
      "\t.p2align\t4\n",
      "\"_.const.missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\":\n",
      "\t.asciz\t\"missing Environment: _ZN08NumbaEnv8__main__7add$247Exx\"\n",
      "\n",
      ".subsections_via_symbols\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v, k in add.inspect_asm().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "Select exercises from the previous notebooks that could be made faster using Numba and investigate what speed-ups you can achieve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
