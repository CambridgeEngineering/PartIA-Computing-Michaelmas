{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 Compuled and interpreted languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "*This notebook is optional and intended for those with an interest in going beyond the course material.*\n",
    "\n",
    "Programming languages and commonly classed as *compiled* or *interpreted*. We summarise and demonstrate some of the differences in this notebook.\n",
    "\n",
    "### Compiled languages\n",
    "\n",
    "A compiled language uses a *compiler* to transform input code into a program (machine code) that is executed by a computer. Machine code is the set of instructions for a computer to execute in the CPUs computers 'native' language (instruction set). It is not human readable. The compiler generally processes the entire program, transforming it in a sequence of steps into machine code.\n",
    "\n",
    "Common and popular compiled languages include C, C++, Fortran and Rust.\n",
    "\n",
    "\n",
    "### Interpreted languages\n",
    "\n",
    "An interpreted language processes program instructions as they are encountered (line-by-line) rather processing the entire program into machine code ahead of time. Python is an interpreted language.\n",
    "\n",
    "\n",
    "### Difference between compiled and interpreted languages\n",
    "\n",
    "Compiled languages lead to programs are generally faster than interpreted programs, although in many cases implementations in an interpreted language are nowadays fast enough for the application needs. Compiled programs can have a smaller memory footprint, which can be important for embedded devices and other platforms with limited capacity. The computer on which a compiled program runs does not need to have a compiler or an interpreter installed.\n",
    "\n",
    "When a compiler translates code into an executable program it will typically perform checks and perform optimisations (static analysis). The compiler checks for valid syntax, and sophisticated optimisations can perform code transformations that make programs faster. Interpreted languages are usually simpler to develop, and more interactive and avoid the need for a compilation step. Interpreted languages are often dynamically typed, with the interpreter inferring the types, e.g. integers versus floats, at runtime, With compiled languages, types are usually fixed at compile time.\n",
    "\n",
    "\n",
    "### Just-in-time compilation\n",
    "\n",
    "The difference between interpreted and compiled languages is not as clear as it once was, with interpreted languages now often using 'just-in-time' compilation. We will explore the impact of compiled code using [Numba](https://numba.pydata.org/), a just-in-time compiler for Python that targets numerical computation. For functions that we specifically annotate, Numba can compile the code and apply performance optimisations typical of compiled languages with the objective of making functions faster.\n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Understand the difference between compiled and interpreted implementations\n",
    "- Explore performance differences between interpreted and compiled implementations\n",
    "- Awareness of intermediate representations and assembly code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will later use `Numba`, so we install it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in /Users/garth/code/fenics/venv/lib/python3.10/site-packages (0.56.2)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /Users/garth/code/fenics/venv/lib/python3.10/site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /Users/garth/code/fenics/venv/lib/python3.10/site-packages (from numba) (1.23.3)\n",
      "Collecting setuptools<60\n",
      "  Using cached setuptools-59.8.0-py3-none-any.whl (952 kB)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.3.0\n",
      "    Uninstalling setuptools-65.3.0:\n",
      "      Successfully uninstalled setuptools-65.3.0\n",
      "Successfully installed setuptools-59.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of interpreted and compiled functions\n",
    "\n",
    "In [07 Numerical computation](07%20Numerical%20computation.ipynb) we tested the performance of a simple function for computing the norm of a long vector. We consider a similar problem here: computing the dot product of a vector with itself, $\\boldsymbol{x} \\cdot \\boldsymbol{x}$, using our own Python function and using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native Python implementation\n",
      "CPU times: user 950 ms, sys: 994 ms, total: 1.94 s\n",
      "Wall time: 747 ms\n",
      "\n",
      " NumPy implementation\n",
      "CPU times: user 5.16 ms, sys: 114 µs, total: 5.27 ms\n",
      "Wall time: 5.18 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def compute_norm2(x):\n",
    "    norm2 = 0.0\n",
    "    for xi in x:\n",
    "        norm2 += xi*xi\n",
    "    return norm2\n",
    "\n",
    "x = np.random.rand(10000000)\n",
    "\n",
    "print(\"Native Python implementation\")\n",
    "%time n0 = compute_norm2(x)\n",
    "\n",
    "print(\"\\n NumPy implementation\")\n",
    "%time n1 = np.dot(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the NumPy code is many orders of magnitude faster. NumPy in fact uses compiled code/library for the computation, which is the reason why it is much faster than our pure Python implementation.\n",
    "\n",
    "We now make a small change and add the 'decorator' `@numba.jit` to our function. This instructs Numba to transform our function in a compiled function/program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba implementation\n",
      "CPU times: user 4.89 ms, sys: 34 µs, total: 4.92 ms\n",
      "Wall time: 4.94 ms\n",
      "\n",
      " NumPy implementation\n",
      "CPU times: user 5.18 ms, sys: 49 µs, total: 5.23 ms\n",
      "Wall time: 5.1 ms\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "\n",
    "@numba.jit(nopython=True,fastmath=True)\n",
    "def compute_norm2(x):\n",
    "    norm2 = 0.0\n",
    "    for xi in x:\n",
    "        norm2 += xi*xi\n",
    "    return norm2\n",
    "\n",
    "x = np.random.rand(10000000)\n",
    "compute_norm2(x)\n",
    "\n",
    "print(\"Numba implementation\")\n",
    "%time n0 = compute_norm2(x)\n",
    "\n",
    "print(\"\\n NumPy implementation\")\n",
    "%time n1 = np.dot(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we call `compute_norm2` twice and time only the second call. We want to measure the raw cost of the computation and not the Numba just-in-time compilation overhead that is incurred the first time a function is processed.\n",
    "\n",
    "The Numba version is much faster than the pure Python version. NumPy is faster again for this operation, but relative close to the Numba time. This is likely because NumPy is using a highly optimised BLAS (Basic Linear Algebra Subprograms) implementation, which is a set of machine code level functions that are highly tuned for basic linear algebra operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "We saw in [10 Algorithms](10%20Algorithms.ipynb) that our implementation of the quicksort algorithm was considerably slower than the Python built-in quicksort. Part of the performance difference could be explained by our implementation being in pure Python, with the built-in Python function being implemented in a compiled language.\n",
    "\n",
    "We can explore the difference compilation might make to our implementation. To start, we reproduce the pure Python quicksort implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_ref(A, lo, hi):\n",
    "    \"\"\"Partitioning function for use in quicksort\"\"\"\n",
    "    pivot = A[hi]\n",
    "    i = lo\n",
    "    for j in range(lo,  hi):\n",
    "        if A[j] <= pivot:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i += 1\n",
    "    A[i], A[hi] = A[hi], A[i]\n",
    "    return i\n",
    "\n",
    "def quicksort_ref(A, lo=0, hi=None):\n",
    "    \"\"\"Sort A and return sorted array\"\"\"\n",
    "\n",
    "    # Initialise data the first time function is called    \n",
    "    if hi is None:\n",
    "        A = A.copy()\n",
    "        hi = len(A) - 1\n",
    "\n",
    "    # Sort    \n",
    "    if lo < hi:\n",
    "        p = partition_ref(A, lo,  hi)\n",
    "        quicksort_ref(A, lo, p - 1)\n",
    "        quicksort_ref(A, p + 1, hi)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now introduce a version annotated with a Numba decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def partition_jit(A, lo, hi,fastmath=True):\n",
    "    \"\"\"Partitioning function for use in quicksort\"\"\"\n",
    "    pivot = A[hi]\n",
    "    i = lo\n",
    "    for j in range(lo,  hi):\n",
    "        if A[j] <= pivot:\n",
    "            A[i], A[j] = A[j], A[i]\n",
    "            i += 1\n",
    "    A[i], A[hi] = A[hi], A[i]\n",
    "    return i\n",
    "\n",
    "@numba.jit(nopython=True,fastmath=True)\n",
    "def quicksort_jit(A, lo=0, hi=-1):\n",
    "    \"\"\"Sort A and return sorted array\"\"\"\n",
    "\n",
    "    # Initialise data the first time function is called    \n",
    "    if hi == -1:\n",
    "        A = A.copy()\n",
    "        hi = len(A) - 1\n",
    "\n",
    "    # Sort    \n",
    "    if lo < hi:\n",
    "        p = partition_jit(A, lo,  hi)\n",
    "        quicksort_jit(A, lo, p - 1)\n",
    "        quicksort_jit(A, p + 1, hi)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last argument to `quicksort_jit` has been changed slightly so that the argument type does not change (argument types that change are problematic for a compiler as it needs to know ahead of time which types to generate machine code for).\n",
    "\n",
    "We can now time our pure Python implementation, the Numba-compiled implementation and the built-in sort function. As before, we will call `quicksort_jit` once before timing to eliminate the cost of the just-in-time compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python implementation\n",
      "CPU times: user 3.75 s, sys: 10.5 ms, total: 3.76 s\n",
      "Wall time: 3.76 s\n",
      "Numba implementation\n",
      "CPU times: user 89.9 ms, sys: 1.15 ms, total: 91 ms\n",
      "Wall time: 91.1 ms\n",
      "Python built-in implementation\n",
      "CPU times: user 77.5 ms, sys: 1.88 ms, total: 79.4 ms\n",
      "Wall time: 80.4 ms\n"
     ]
    }
   ],
   "source": [
    "data = np.random.rand(1000000)\n",
    "\n",
    "# Time the pure Python implementation\n",
    "print(\"Pure Python implementation\")\n",
    "%time x = quicksort_ref(data)\n",
    "\n",
    "# Time the Numba implementation\n",
    "quicksort_jit(data)\n",
    "print(\"Numba implementation\")\n",
    "%time x = quicksort_jit(data)\n",
    "\n",
    "# Time the built-in implementation\n",
    "print(\"Python built-in implementation\")\n",
    "%time x = np.sort(data, kind='quicksort')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pure Python implementation is clearly the slowest. The Numba and built-in implementation are relatively close in time. Note that the Numba implementation is virtually a direct translation of the pure Python implementation and has not been carefully optimised. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate representations and assembly code\n",
    "\n",
    "A compiler translates input code into (i) an 'intermediate representation' (IR), and then into (ii) machine code. The IR is the compiler's internal representation of a program. A compiler can perform optimisations on the IR that may make a program faster and which may be specific to the CPU type. Machine code is the low instructions sent to the CPU.\n",
    "\n",
    "With Numba we can inspect the IR and the assembly code. Assembly code is human readable code (but very low level) that maps almost one-to-one to machine code (which would be very hard to read).\n",
    "\n",
    "Consider a very simple function that returns the sum of two integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import int64\n",
    "\n",
    "@numba.jit('int64(int64, int64)', nopython=True)\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "add(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that we have specified the argument types in this case.\n",
    "\n",
    "\n",
    "### Intermediate representation\n",
    "\n",
    "We can inspect the compiler's IR for the this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "; ModuleID = 'add'\n",
      "source_filename = \"<string>\"\n",
      "target datalayout = \"e-m:o-i64:64-i128:128-n32:64-S128\"\n",
      "target triple = \"arm64-apple-darwin21.6.0\"\n",
      "\n",
      "@_ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx = common local_unnamed_addr global i8* null\n",
      "@.const.add = internal constant [4 x i8] c\"add\\00\"\n",
      "@PyExc_RuntimeError = external global i8\n",
      "@\".const.missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\" = internal constant [96 x i8] c\"missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\\00\"\n",
      "\n",
      "; Function Attrs: nofree norecurse nounwind writeonly\n",
      "define i32 @_ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx(i64* noalias nocapture %retptr, { i8*, i32, i8* }** noalias nocapture readnone %excinfo, i64 %arg.x, i64 %arg.y) local_unnamed_addr #0 {\n",
      "entry:\n",
      "  %.6 = add nsw i64 %arg.y, %arg.x\n",
      "  store i64 %.6, i64* %retptr, align 8\n",
      "  ret i32 0\n",
      "}\n",
      "\n",
      "define i8* @_ZN7cpython8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx(i8* nocapture readnone %py_closure, i8* %py_args, i8* nocapture readnone %py_kws) local_unnamed_addr {\n",
      "entry:\n",
      "  %.5 = alloca i8*, align 8\n",
      "  %.6 = alloca i8*, align 8\n",
      "  %.7 = call i32 (i8*, i8*, i64, i64, ...) @PyArg_UnpackTuple(i8* %py_args, i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.const.add, i64 0, i64 0), i64 2, i64 2, i8** nonnull %.5, i8** nonnull %.6)\n",
      "  %.8 = icmp eq i32 %.7, 0\n",
      "  %.53 = alloca i64, align 8\n",
      "  store i64 0, i64* %.53, align 8\n",
      "  br i1 %.8, label %entry.if, label %entry.endif, !prof !0\n",
      "\n",
      "entry.if:                                         ; preds = %entry.endif.endif.endif.endif.endif, %entry.endif.endif.endif, %entry\n",
      "  ret i8* null\n",
      "\n",
      "entry.endif:                                      ; preds = %entry\n",
      "  %.12 = load i8*, i8** @_ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx, align 8\n",
      "  %.17 = icmp eq i8* %.12, null\n",
      "  br i1 %.17, label %entry.endif.if, label %entry.endif.endif, !prof !0\n",
      "\n",
      "entry.endif.if:                                   ; preds = %entry.endif\n",
      "  call void @PyErr_SetString(i8* nonnull @PyExc_RuntimeError, i8* getelementptr inbounds ([96 x i8], [96 x i8]* @\".const.missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\", i64 0, i64 0))\n",
      "  ret i8* null\n",
      "\n",
      "entry.endif.endif:                                ; preds = %entry.endif\n",
      "  %.21 = load i8*, i8** %.5, align 8\n",
      "  %.24 = call i8* @PyNumber_Long(i8* %.21)\n",
      "  %.25.not = icmp eq i8* %.24, null\n",
      "  br i1 %.25.not, label %entry.endif.endif.endif, label %entry.endif.endif.if, !prof !0\n",
      "\n",
      "entry.endif.endif.if:                             ; preds = %entry.endif.endif\n",
      "  %.27 = call i64 @PyLong_AsLongLong(i8* nonnull %.24)\n",
      "  call void @Py_DecRef(i8* nonnull %.24)\n",
      "  br label %entry.endif.endif.endif\n",
      "\n",
      "entry.endif.endif.endif:                          ; preds = %entry.endif.endif, %entry.endif.endif.if\n",
      "  %.22.0 = phi i64 [ %.27, %entry.endif.endif.if ], [ 0, %entry.endif.endif ]\n",
      "  %.32 = call i8* @PyErr_Occurred()\n",
      "  %.33.not = icmp eq i8* %.32, null\n",
      "  br i1 %.33.not, label %entry.endif.endif.endif.endif, label %entry.if, !prof !1\n",
      "\n",
      "entry.endif.endif.endif.endif:                    ; preds = %entry.endif.endif.endif\n",
      "  %.37 = load i8*, i8** %.6, align 8\n",
      "  %.40 = call i8* @PyNumber_Long(i8* %.37)\n",
      "  %.41.not = icmp eq i8* %.40, null\n",
      "  br i1 %.41.not, label %entry.endif.endif.endif.endif.endif, label %entry.endif.endif.endif.endif.if, !prof !0\n",
      "\n",
      "entry.endif.endif.endif.endif.if:                 ; preds = %entry.endif.endif.endif.endif\n",
      "  %.43 = call i64 @PyLong_AsLongLong(i8* nonnull %.40)\n",
      "  call void @Py_DecRef(i8* nonnull %.40)\n",
      "  br label %entry.endif.endif.endif.endif.endif\n",
      "\n",
      "entry.endif.endif.endif.endif.endif:              ; preds = %entry.endif.endif.endif.endif, %entry.endif.endif.endif.endif.if\n",
      "  %.38.0 = phi i64 [ %.43, %entry.endif.endif.endif.endif.if ], [ 0, %entry.endif.endif.endif.endif ]\n",
      "  %.48 = call i8* @PyErr_Occurred()\n",
      "  %.49.not = icmp eq i8* %.48, null\n",
      "  br i1 %.49.not, label %entry.endif.endif.endif.endif.endif.endif, label %entry.if, !prof !1\n",
      "\n",
      "entry.endif.endif.endif.endif.endif.endif:        ; preds = %entry.endif.endif.endif.endif.endif\n",
      "  store i64 0, i64* %.53, align 8\n",
      "  %.57 = call i32 @_ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx(i64* nonnull %.53, { i8*, i32, i8* }** undef, i64 %.22.0, i64 %.38.0) #2\n",
      "  %.67 = load i64, i64* %.53, align 8\n",
      "  %.74 = call i8* @PyLong_FromLongLong(i64 %.67)\n",
      "  ret i8* %.74\n",
      "}\n",
      "\n",
      "declare i32 @PyArg_UnpackTuple(i8*, i8*, i64, i64, ...) local_unnamed_addr\n",
      "\n",
      "declare void @PyErr_SetString(i8*, i8*) local_unnamed_addr\n",
      "\n",
      "declare i8* @PyNumber_Long(i8*) local_unnamed_addr\n",
      "\n",
      "declare i64 @PyLong_AsLongLong(i8*) local_unnamed_addr\n",
      "\n",
      "declare void @Py_DecRef(i8*) local_unnamed_addr\n",
      "\n",
      "declare i8* @PyErr_Occurred() local_unnamed_addr\n",
      "\n",
      "declare i8* @PyLong_FromLongLong(i64) local_unnamed_addr\n",
      "\n",
      "; Function Attrs: nofree norecurse nounwind writeonly\n",
      "define i64 @cfunc._ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx(i64 %.1, i64 %.2) local_unnamed_addr #0 {\n",
      "entry:\n",
      "  %.4 = alloca i64, align 8\n",
      "  store i64 0, i64* %.4, align 8\n",
      "  %.8 = call i32 @_ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx(i64* nonnull %.4, { i8*, i32, i8* }** undef, i64 %.1, i64 %.2) #2\n",
      "  %.18 = load i64, i64* %.4, align 8\n",
      "  ret i64 %.18\n",
      "}\n",
      "\n",
      "; Function Attrs: nounwind\n",
      "declare void @llvm.stackprotector(i8*, i8**) #1\n",
      "\n",
      "attributes #0 = { nofree norecurse nounwind writeonly }\n",
      "attributes #1 = { nounwind }\n",
      "attributes #2 = { noinline }\n",
      "\n",
      "!0 = !{!\"branch_weights\", i32 1, i32 99}\n",
      "!1 = !{!\"branch_weights\", i32 99, i32 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v, k in add.inspect_llvm().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IR would be of interest to someone designing compilers or seeing the optimisation transformations that a compiler might perform.\n",
    "\n",
    "### Assembly code\n",
    "\n",
    "In some very special cases it can be helpful to inspect the assembly code, which is the closest to readable version of CPU instructions. It is usually inspected only in cases where an understanding of the lowest level operations is required, e.g. when extreme performance is necessary. It is specific to a CPU architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t.section\t__TEXT,__text,regular,pure_instructions\n",
      "\t.build_version macos, 12, 0\n",
      "\t.globl\t__ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\n",
      "\t.p2align\t2\n",
      "__ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx:\n",
      "\tadd\tx8, x3, x2\n",
      "\tstr\tx8, [x0]\n",
      "\tmov\tw0, #0\n",
      "\tret\n",
      "\n",
      "\t.globl\t__ZN7cpython8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\n",
      "\t.p2align\t2\n",
      "__ZN7cpython8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx:\n",
      "\t.cfi_startproc\n",
      "\tsub\tsp, sp, #112\n",
      "\tstp\tx24, x23, [sp, #48]\n",
      "\tstp\tx22, x21, [sp, #64]\n",
      "\tstp\tx20, x19, [sp, #80]\n",
      "\tstp\tx29, x30, [sp, #96]\n",
      "\t.cfi_def_cfa_offset 112\n",
      "\t.cfi_offset w30, -8\n",
      "\t.cfi_offset w29, -16\n",
      "\t.cfi_offset w19, -24\n",
      "\t.cfi_offset w20, -32\n",
      "\t.cfi_offset w21, -40\n",
      "\t.cfi_offset w22, -48\n",
      "\t.cfi_offset w23, -56\n",
      "\t.cfi_offset w24, -64\n",
      "\tmov\tx0, x1\n",
      "\tadd\tx8, sp, #32\n",
      "\tadd\tx9, sp, #40\n",
      "\tstp\tx9, x8, [sp]\n",
      "Lloh0:\n",
      "\tadrp\tx1, _.const.add@GOTPAGE\n",
      "Lloh1:\n",
      "\tldr\tx1, [x1, _.const.add@GOTPAGEOFF]\n",
      "Lloh2:\n",
      "\tadrp\tx8, _PyArg_UnpackTuple@GOTPAGE\n",
      "Lloh3:\n",
      "\tldr\tx8, [x8, _PyArg_UnpackTuple@GOTPAGEOFF]\n",
      "\tmov\tw2, #2\n",
      "\tmov\tw3, #2\n",
      "\tblr\tx8\n",
      "\tstr\txzr, [sp, #24]\n",
      "\tcbz\tw0, LBB1_9\n",
      "Lloh4:\n",
      "\tadrp\tx8, __ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGE\n",
      "Lloh5:\n",
      "\tldr\tx8, [x8, __ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGEOFF]\n",
      "Lloh6:\n",
      "\tldr\tx8, [x8]\n",
      "\tcbz\tx8, LBB1_8\n",
      "\tldr\tx0, [sp, #40]\n",
      "Lloh7:\n",
      "\tadrp\tx21, _PyNumber_Long@GOTPAGE\n",
      "Lloh8:\n",
      "\tldr\tx21, [x21, _PyNumber_Long@GOTPAGEOFF]\n",
      "\tblr\tx21\n",
      "Lloh9:\n",
      "\tadrp\tx23, _PyLong_AsLongLong@GOTPAGE\n",
      "Lloh10:\n",
      "\tldr\tx23, [x23, _PyLong_AsLongLong@GOTPAGEOFF]\n",
      "Lloh11:\n",
      "\tadrp\tx22, _Py_DecRef@GOTPAGE\n",
      "Lloh12:\n",
      "\tldr\tx22, [x22, _Py_DecRef@GOTPAGEOFF]\n",
      "\tcbz\tx0, LBB1_10\n",
      "\tmov\tx20, x0\n",
      "\tblr\tx23\n",
      "\tmov\tx19, x0\n",
      "\tmov\tx0, x20\n",
      "\tblr\tx22\n",
      "Lloh13:\n",
      "\tadrp\tx24, _PyErr_Occurred@GOTPAGE\n",
      "Lloh14:\n",
      "\tldr\tx24, [x24, _PyErr_Occurred@GOTPAGEOFF]\n",
      "\tblr\tx24\n",
      "\tcbnz\tx0, LBB1_9\n",
      "LBB1_4:\n",
      "\tldr\tx0, [sp, #32]\n",
      "\tblr\tx21\n",
      "\tcbz\tx0, LBB1_11\n",
      "\tmov\tx21, x0\n",
      "\tblr\tx23\n",
      "\tmov\tx20, x0\n",
      "\tmov\tx0, x21\n",
      "\tblr\tx22\n",
      "\tblr\tx24\n",
      "\tcbnz\tx0, LBB1_9\n",
      "LBB1_6:\n",
      "\tstr\txzr, [sp, #24]\n",
      "Lloh15:\n",
      "\tadrp\tx8, __ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGE\n",
      "Lloh16:\n",
      "\tldr\tx8, [x8, __ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGEOFF]\n",
      "\tadd\tx0, sp, #24\n",
      "\tmov\tx2, x19\n",
      "\tmov\tx3, x20\n",
      "\tblr\tx8\n",
      "\tldr\tx0, [sp, #24]\n",
      "Lloh17:\n",
      "\tadrp\tx8, _PyLong_FromLongLong@GOTPAGE\n",
      "Lloh18:\n",
      "\tldr\tx8, [x8, _PyLong_FromLongLong@GOTPAGEOFF]\n",
      "\tblr\tx8\n",
      "LBB1_7:\n",
      "\tldp\tx29, x30, [sp, #96]\n",
      "\tldp\tx20, x19, [sp, #80]\n",
      "\tldp\tx22, x21, [sp, #64]\n",
      "\tldp\tx24, x23, [sp, #48]\n",
      "\tadd\tsp, sp, #112\n",
      "\tret\n",
      "LBB1_8:\n",
      "Lloh19:\n",
      "\tadrp\tx0, _PyExc_RuntimeError@GOTPAGE\n",
      "Lloh20:\n",
      "\tldr\tx0, [x0, _PyExc_RuntimeError@GOTPAGEOFF]\n",
      "Lloh21:\n",
      "\tadrp\tx1, \"_.const.missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\"@GOTPAGE\n",
      "Lloh22:\n",
      "\tldr\tx1, [x1, \"_.const.missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\"@GOTPAGEOFF]\n",
      "Lloh23:\n",
      "\tadrp\tx8, _PyErr_SetString@GOTPAGE\n",
      "Lloh24:\n",
      "\tldr\tx8, [x8, _PyErr_SetString@GOTPAGEOFF]\n",
      "\tblr\tx8\n",
      "LBB1_9:\n",
      "\tmov\tx0, #0\n",
      "\tb\tLBB1_7\n",
      "LBB1_10:\n",
      "\tmov\tx19, #0\n",
      "Lloh25:\n",
      "\tadrp\tx24, _PyErr_Occurred@GOTPAGE\n",
      "Lloh26:\n",
      "\tldr\tx24, [x24, _PyErr_Occurred@GOTPAGEOFF]\n",
      "\tblr\tx24\n",
      "\tcbz\tx0, LBB1_4\n",
      "\tb\tLBB1_9\n",
      "LBB1_11:\n",
      "\tmov\tx20, #0\n",
      "\tblr\tx24\n",
      "\tcbz\tx0, LBB1_6\n",
      "\tb\tLBB1_9\n",
      "\t.loh AdrpLdrGot\tLloh2, Lloh3\n",
      "\t.loh AdrpLdrGot\tLloh0, Lloh1\n",
      "\t.loh AdrpLdrGotLdr\tLloh4, Lloh5, Lloh6\n",
      "\t.loh AdrpLdrGot\tLloh11, Lloh12\n",
      "\t.loh AdrpLdrGot\tLloh9, Lloh10\n",
      "\t.loh AdrpLdrGot\tLloh7, Lloh8\n",
      "\t.loh AdrpLdrGot\tLloh13, Lloh14\n",
      "\t.loh AdrpLdrGot\tLloh17, Lloh18\n",
      "\t.loh AdrpLdrGot\tLloh15, Lloh16\n",
      "\t.loh AdrpLdrGot\tLloh23, Lloh24\n",
      "\t.loh AdrpLdrGot\tLloh21, Lloh22\n",
      "\t.loh AdrpLdrGot\tLloh19, Lloh20\n",
      "\t.loh AdrpLdrGot\tLloh25, Lloh26\n",
      "\t.cfi_endproc\n",
      "\n",
      "\t.globl\t_cfunc._ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\n",
      "\t.p2align\t2\n",
      "_cfunc._ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx:\n",
      "\tsub\tsp, sp, #32\n",
      "\tstp\tx29, x30, [sp, #16]\n",
      "\tmov\tx2, x0\n",
      "\tstr\txzr, [sp, #8]\n",
      "Lloh27:\n",
      "\tadrp\tx8, __ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGE\n",
      "Lloh28:\n",
      "\tldr\tx8, [x8, __ZN8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx@GOTPAGEOFF]\n",
      "\tadd\tx0, sp, #8\n",
      "\tmov\tx3, x1\n",
      "\tblr\tx8\n",
      "\tldr\tx0, [sp, #8]\n",
      "\tldp\tx29, x30, [sp, #16]\n",
      "\tadd\tsp, sp, #32\n",
      "\tret\n",
      "\t.loh AdrpLdrGot\tLloh27, Lloh28\n",
      "\n",
      "\t.comm\t__ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx,8,3\n",
      "\t.section\t__TEXT,__const\n",
      "_.const.add:\n",
      "\t.asciz\t\"add\"\n",
      "\n",
      "\t.p2align\t4\n",
      "\"_.const.missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\":\n",
      "\t.asciz\t\"missing Environment: _ZN08NumbaEnv8__main__3addB2v9B38c8tJTIcFHzwl2ILiXkcBV0KBSgP9CGZpAgA_3dExx\"\n",
      "\n",
      ".subsections_via_symbols\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v, k in add.inspect_asm().items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Select exercises from the previous notebooks that could be made faster using Numba and investigate what speed-ups you can achieve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
